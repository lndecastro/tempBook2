# Module 7 â€” Foundational Models and Tools

AI today is powered by large, generalâ€‘purpose systems known as **Foundational Models**. These models, trained on massive datasets, are capable of many tasks and underpin the **AI tools** we use daily. This module connects the conceptual foundations we have studied so far (Modules 1â€“6) with practical engagement, preparing you for Module 8â€™s case studies.

## Learning Objectives

After completing this module, you will be able to:
- Define **foundational models** and distinguish them from taskâ€‘specific models.
- Identify major **model families** (language, vision, multimodal, code) and where theyâ€™re used.
- Navigate the **tooling ecosystem** (assistants, copilots, openâ€‘source stacks, deployment options).
- Customize models responsibly using **prompting**, **context engineering**, **RAG**, and lightâ€‘weight **adapters**.
- Build simple **Projects/workflows** that combine models, data, and evaluation.
- Apply **responsible AI** practices: privacy, safety, transparency, and basic model evaluation.

## ğŸ§  Part I â€” What Are Foundational Models?

**Foundational Models** are large, preâ€‘trained AI systems adapted to many downstream tasks. They provide a **common base of knowledge and reasoning** for specialized applications.

**Families & exemplars (illustrative):**
- **Language** â€” general LLMs for writing, QA, tutoring.
- **Vision** â€” image understanding, detection, segmentation.
- **Multimodal** â€” models that handle text + image + audio/video.
- **Code** â€” code completion, explanation, refactoring, tests.

### Key Characteristics

| Feature | Description |
|:--|:--|
| **Scale** | Trained on very large corpora with highâ€‘performance compute. |
| **Transferability** | Adapt to new tasks with little additional data. |
| **Multimodality** | Process multiple data types (text, image, audio, code). |
| **Emergent Behavior** | Capabilities not explicitly programmed may appear. |
| **Alignment** | Instructionâ€‘tuning & feedback align models to human intent and safety. |

> **Key message:** Foundational models are **bases** you shape with context and lightweight adaptation.

---

## âš™ï¸ Part II â€” The Tooling Landscape

Below is a layered view of how **infrastructure**, **data/knowledge**, **methods**, and **applications** fit together.

```mermaid
flowchart TB
  subgraph L0[Infrastructure Layer]
    C1[Compute:\nGPUs/TPUs, Edge/Cloud, HPC]
    S1[Storage:\nData Lakes, Warehouses, Object Stores]
    P1[Pipelines:\nStreaming, Batch, ETL/ELT]
    F1[Frameworks:\nSpark, Ray, Hadoop/Flink]
  end

  subgraph L1[Data & Knowledge Layer]
    D1[Big Data (5Vs)]
    D2[Data Science]
    D3[KDD âœ Data Mining]
    D4[NLP Corpora & Tools]
  end

  subgraph L2[Method Layer]
    M1[Symbolic AI]
    M2[Machine Learning]
    M3[Deep Learning]
    M4[Computational Intelligence]
    M5[Natural Computing]
    M6[Soft Computing (hybrids)]
  end

  subgraph L3[Application Layer]
    A1[Vision & Perception]
    A2[Speech & Language (NLP)]
    A3[Recommenders & Personalization]
    A4[Robotics & Control]
    A5[Decision Support & Analytics]
    A6[Generative AI (text/image/code/audio/video)]
  end

  C1 --> L1
  S1 --> L1
  P1 --> L1
  F1 --> L1
  L1 --> L2
  L2 --> L3
```

**Categories & examples:**  
- **General assistants:** multiâ€‘purpose chat + reasoning (summaries, QA, analysis).  
- **Copilots (embedded AI):** productivity suites (docs/slides/email), IDEs, design tools.  
- **Openâ€‘source/local:** model hubs and runtimes for custom deployment.  
- **Connectors:** files (PDF/CSV), vectors, retrieval, and toolâ€‘use integrations.

---

## ğŸ§© Part III â€” Customization Patterns (No/Lowâ€‘Code First)

1) **Prompting & Context Engineering (recap of Modules 5â€“6)**  
Roles, constraints, audience, output contracts; guardrail instructions (cite sources, allow â€œI donâ€™t knowâ€).

2) **RAG (Retrievalâ€‘Augmented Generation) â€” Concept**  
When to use RAG: grounding, citations, upâ€‘toâ€‘date facts. Highâ€‘level flow: **ingest â†’ chunk/index â†’ retrieve â†’ generate**.

```mermaid
sequenceDiagram
  participant U as User Query
  participant R as Retriever (Vector/Keyword)
  participant K as Knowledge Store
  participant L as LLM (Generator)
  U->>R: Ask question
  R->>K: Search relevant chunks
  K-->>R: Return topâ€‘k passages
  R-->>L: Provide context snippets
  L-->>U: Grounded answer + citations
```

3) **Adapters & Light Fineâ€‘Tuning (conceptual)**  
LoRA/adapters to shape style or domain responses; use only when prompting + RAG are insufficient.

4) **Function/Tool Use (conceptual)**  
Let models call calculators, tables, or APIs; improves reliability for tasks like math or structured outputs.

> **Rule of thumb:** escalate from **prompting â†’ context â†’ RAG â†’ adapters** only as needed.

---

## ğŸ§® Part IV â€” Projects & Workflows (Handsâ€‘On Miniâ€‘Labs)

Below are **four labs** you can run in ChatGPT (Custom GPT or Projects) or a comparable environment.

### Lab 1 â€” Doc QA with Grounding (RAGâ€‘lite)

**Goal:** Ask questions about your own documents with sourced answers.  
**Setup:** Upload 2â€“3 short PDFs/Markdown files (policy/syllabus/guide).  

**Prompt shell:**
```
System: You are a careful analyst. Only answer using uploaded files. If unsure, say â€œI donâ€™t know.â€
Task: Answer the question below with paragraphâ€‘level citations (file name + page/heading).
Question: <your question>
Output format: Markdown with a short answer, bullet citations, and a 1â€‘sentence caveat.
```

**Deliverable:** A Q&A snippet with **citations** and a oneâ€‘line caveat.

---

### Lab 2 â€” Data Explainer (Small CSV)

**Goal:** Turn a small CSV into quick understanding.  
**Setup:** Upload a tiny CSV (â‰¤ 1â€“2 KB per column; e.g., 100â€“500 rows).  

**Prompt shell:**
```
System: You are a data analyst. If no code execution is available, describe the method; do not fabricate numbers.
Task:
1) Create a column dictionary (name, inferred type, note).
2) List 5 quality checks (nulls, ranges, duplicates, outliers, consistency).
3) Provide 5 insights framed as observations + implications.
4) Suggest one chart with title, axes, and why it helps.
Output: Markdown tables where appropriate.
```

**Deliverable:** Column dictionary, checks, insights, and a chart brief.

---

### Lab 3 â€” Policy/Guideline Assistant (Grounded Answers)

**Goal:** Answer FAQs from a policy or guideline with references.  
**Setup:** Upload one policy/guideline PDF or MD file.  

**Prompt shell:**
```
System: You are a policy assistant. Quote or paraphrase only from the uploaded file; include section/heading references.
Task: Answer the following 5 FAQs as short paragraphs with a bullet list of cited sections.
Constraints: If content is not in the file, respond â€œNot specified in the provided policy.â€
```

**Deliverable:** 5 grounded answers + citations.

---

### Lab 4 â€” Quick Custom GPT / Project

**Goal:** Create a small, reusable workspace/assistant.  
**Setup:** In Custom GPTs or Projects, add: instructions, 2 reference files, and a preferred output schema.  

**Instruction template (paste into Custom GPT/Project):**
```
Role & Purpose: Act as <role> (e.g., course tutor, policy assistant). Answer only using the uploaded references when possible.
Audience & Tone: <define audience>; clear, concise, cite sections; allow â€œI donâ€™t knowâ€ when unsure.
Output Contract: Use Markdown; include a brief caveat and a short checklist or action items at the end.
Limits & Safety: No private/sensitive data; do not make legal/medical decisions; defer to humans for critical judgments.
```

**Test queries (examples):**
- â€œSummarize the main requirements in one paragraph with 3 cited bullets.â€  
- â€œExtract 5 FAQs with answers and section references.â€

**Deliverable:** A short transcript (2â€“3 exchanges) and one final answer artifact.

---

## ğŸ”’ Part V â€” Responsible & Humanâ€‘Centered Use

**Principles:** transparency, privacy, fairness, and proportionality of use.  
**Practices:** disclose AI assistance; deâ€‘identify sensitive data; verify claims; permit â€œI donâ€™t know.â€

> Download the **Reliability & Responsibility Checklist** and include it in your Lab submissions.

- [Download: Module 7 Reliability & Responsibility Checklist (Markdown)](Module7_Reliability_Checklist.md)

---

## ğŸ§­ Part VI â€” Putting It Together (Bridge to Module 8)

Choose one domain (education, healthcare, environment, business, arts) and build a **Project** that:
1) Loads references/data.  
2) Answers 3 task types (Q&A, summary, structured output).  
3) Outputs a short report with a caveat and next steps.  
4) Uses the checklist to selfâ€‘evaluate.

---

## ğŸ“˜ Further Reading (vendorâ€‘neutral)
- Foundation models: opportunities & risks; alignment and safety overviews.
- Concept primers on **RAG**, **instructionâ€‘tuning**, and **tool use**.
- Practical guides on disclosure, privacy, and basic evaluation rubrics.

---

## âœ… What you should leave with
- A mental model of **which tool/model to use when**.
- Confidence to **ground** outputs in your own materials.
- A reusable **workflow template** (Projects/Custom GPT) to carry into Module 8.

